{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Implementaiton with CNN - Improving accuracy #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/700/1*5A4b1qOZIr4Q6SKceqGn7w.jpeg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST handwritten digit data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#Lets do a min max scaling to make it between 0 & 1. This will be good for us in training.\n",
    "X_train=(X_train - X_train.min()) /(X_train.max() - X_train.min())\n",
    "X_test=(X_test - X_test.min()) /(X_test.max() - X_test.min())\n",
    "\n",
    "# Convert y_train into one-hot format \n",
    "y_train_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_hot = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape dataset to have a single channel. Keras conv2d expects a 4 dim vector input\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly trying with a convolution layer and a pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4732)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               605824    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 607,394\n",
      "Trainable params: 607,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2102 - acc: 0.9373 - val_loss: 0.0886 - val_acc: 0.9722\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0897 - acc: 0.9720 - val_loss: 0.0650 - val_acc: 0.9800\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.0636 - acc: 0.9797 - val_loss: 0.0525 - val_acc: 0.9832\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0475 - acc: 0.9844 - val_loss: 0.0525 - val_acc: 0.9831\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0392 - acc: 0.9873 - val_loss: 0.0548 - val_acc: 0.9836\n",
      "Train: 0.995, Test: 0.984\n"
     ]
    }
   ],
   "source": [
    "# Create simple Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())                         # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))   # Output layer 10 neurons\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "\n",
    "# Train the Neural Network model\n",
    "model.fit(X_train, y_train_hot, epochs=5,validation_data=(X_test,y_test_hot))\n",
    "# evaluate the model...Verbose=0 is used to avoid report displays\n",
    "_, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got 98.3% accuracy with in 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now gonna try with different loss functions and optimizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaing lists of optimizers and loss functions\n",
    "loss=['categorical_crossentropy','kl_divergence','poisson','sparse_categorical_crossentropy']\n",
    "opt=['Adadelta','Adagrad','Adam','Adamax','Nadam','RMSprop','SGD']\n",
    "# Creating a dataframe for keeping results\n",
    "df=pd.DataFrame(columns =['Loss','Optimizer','Train Accuracy','Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: categorical_crossentropy, Optimizer: Adadelta, Train: 89.495, Test: 90.430\n",
      "Loss: categorical_crossentropy, Optimizer: Adagrad, Train: 95.358, Test: 95.480\n",
      "Loss: categorical_crossentropy, Optimizer: Adam, Train: 99.948, Test: 98.550\n",
      "Loss: categorical_crossentropy, Optimizer: Adamax, Train: 99.925, Test: 98.650\n",
      "Loss: categorical_crossentropy, Optimizer: Nadam, Train: 99.952, Test: 98.540\n",
      "Loss: categorical_crossentropy, Optimizer: RMSprop, Train: 99.970, Test: 98.590\n",
      "Loss: categorical_crossentropy, Optimizer: SGD, Train: 98.987, Test: 98.040\n",
      "Loss: kl_divergence, Optimizer: Adadelta, Train: 89.315, Test: 90.120\n",
      "Loss: kl_divergence, Optimizer: Adagrad, Train: 95.315, Test: 95.350\n",
      "Loss: kl_divergence, Optimizer: Adam, Train: 99.955, Test: 98.540\n",
      "Loss: kl_divergence, Optimizer: Adamax, Train: 99.887, Test: 98.490\n",
      "Loss: kl_divergence, Optimizer: Nadam, Train: 99.962, Test: 98.610\n",
      "Loss: kl_divergence, Optimizer: RMSprop, Train: 99.943, Test: 98.490\n",
      "Loss: kl_divergence, Optimizer: SGD, Train: 99.070, Test: 98.110\n",
      "Loss: poisson, Optimizer: Adadelta, Train: 85.675, Test: 86.630\n",
      "Loss: poisson, Optimizer: Adagrad, Train: 91.458, Test: 92.060\n",
      "Loss: poisson, Optimizer: Adam, Train: 99.970, Test: 98.530\n",
      "Loss: poisson, Optimizer: Adamax, Train: 99.932, Test: 98.820\n",
      "Loss: poisson, Optimizer: Nadam, Train: 99.935, Test: 98.490\n",
      "Loss: poisson, Optimizer: RMSprop, Train: 99.940, Test: 98.570\n",
      "Loss: poisson, Optimizer: SGD, Train: 95.718, Test: 95.720\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adadelta, Train: 89.100, Test: 89.900\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adagrad, Train: 95.213, Test: 95.110\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adam, Train: 99.952, Test: 98.630\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adamax, Train: 99.953, Test: 98.790\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Nadam, Train: 99.962, Test: 98.590\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: RMSprop, Train: 99.935, Test: 98.370\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: SGD, Train: 99.005, Test: 98.230\n"
     ]
    }
   ],
   "source": [
    "# Looping through all the possibilities with 50 Epocs.. This will run for a few hours.\n",
    "for l in loss:\n",
    "    for o in opt:\n",
    "        model=Sequential([  Conv2D(28, kernel_size=(3,3), input_shape=(28,28,1)),\n",
    "                            MaxPooling2D(pool_size=(2, 2)),\n",
    "                            Flatten(),\n",
    "                            Dense(128, activation='relu'),\n",
    "                            Dropout(0.2),\n",
    "                            Dense(10,activation='softmax')  ])                         \n",
    "        model.compile(optimizer=o, loss=l, metrics=['acc'])\n",
    "        if l == 'sparse_categorical_crossentropy': # No one hot encoding required for this\n",
    "            model.fit(X_train,y_train,epochs=20,validation_data=(X_test,y_test),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        else :\n",
    "            model.fit(X_train,y_train_hot,epochs=20,validation_data=(X_test,y_test_hot),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "        print('Loss: %s, Optimizer: %s, Train: %.3f, Test: %.3f' % (l,o,train_acc*100, test_acc*100))\n",
    "        df = df.append({'Loss':l,'Optimizer':o,'Train Accuracy':train_acc*100,'Test Accuracy':test_acc*100}, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.931669</td>\n",
       "      <td>98.820001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.953336</td>\n",
       "      <td>98.790002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.924999</td>\n",
       "      <td>98.650002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.951667</td>\n",
       "      <td>98.629999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.961668</td>\n",
       "      <td>98.610002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.970001</td>\n",
       "      <td>98.589998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.961668</td>\n",
       "      <td>98.589998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poisson</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.940002</td>\n",
       "      <td>98.570001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.948335</td>\n",
       "      <td>98.549998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.951667</td>\n",
       "      <td>98.540002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.954998</td>\n",
       "      <td>98.540002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.970001</td>\n",
       "      <td>98.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.935001</td>\n",
       "      <td>98.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.943334</td>\n",
       "      <td>98.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.886668</td>\n",
       "      <td>98.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.935001</td>\n",
       "      <td>98.369998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.005002</td>\n",
       "      <td>98.229998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.070001</td>\n",
       "      <td>98.110002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>98.986667</td>\n",
       "      <td>98.040003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>poisson</td>\n",
       "      <td>SGD</td>\n",
       "      <td>95.718336</td>\n",
       "      <td>95.719999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>95.358336</td>\n",
       "      <td>95.480001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>95.314997</td>\n",
       "      <td>95.349997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>95.213336</td>\n",
       "      <td>95.109999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>91.458333</td>\n",
       "      <td>92.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>89.494997</td>\n",
       "      <td>90.429997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>89.314997</td>\n",
       "      <td>90.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>89.099997</td>\n",
       "      <td>89.899999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>85.675001</td>\n",
       "      <td>86.629999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Loss Optimizer  Train Accuracy  Test Accuracy\n",
       "0                           poisson    Adamax       99.931669      98.820001\n",
       "1   sparse_categorical_crossentropy    Adamax       99.953336      98.790002\n",
       "2          categorical_crossentropy    Adamax       99.924999      98.650002\n",
       "3   sparse_categorical_crossentropy      Adam       99.951667      98.629999\n",
       "4                     kl_divergence     Nadam       99.961668      98.610002\n",
       "5          categorical_crossentropy   RMSprop       99.970001      98.589998\n",
       "6   sparse_categorical_crossentropy     Nadam       99.961668      98.589998\n",
       "7                           poisson   RMSprop       99.940002      98.570001\n",
       "8          categorical_crossentropy      Adam       99.948335      98.549998\n",
       "9          categorical_crossentropy     Nadam       99.951667      98.540002\n",
       "10                    kl_divergence      Adam       99.954998      98.540002\n",
       "11                          poisson      Adam       99.970001      98.530000\n",
       "12                          poisson     Nadam       99.935001      98.490000\n",
       "13                    kl_divergence   RMSprop       99.943334      98.490000\n",
       "14                    kl_divergence    Adamax       99.886668      98.490000\n",
       "15  sparse_categorical_crossentropy   RMSprop       99.935001      98.369998\n",
       "16  sparse_categorical_crossentropy       SGD       99.005002      98.229998\n",
       "17                    kl_divergence       SGD       99.070001      98.110002\n",
       "18         categorical_crossentropy       SGD       98.986667      98.040003\n",
       "19                          poisson       SGD       95.718336      95.719999\n",
       "20         categorical_crossentropy   Adagrad       95.358336      95.480001\n",
       "21                    kl_divergence   Adagrad       95.314997      95.349997\n",
       "22  sparse_categorical_crossentropy   Adagrad       95.213336      95.109999\n",
       "23                          poisson   Adagrad       91.458333      92.060000\n",
       "24         categorical_crossentropy  Adadelta       89.494997      90.429997\n",
       "25                    kl_divergence  Adadelta       89.314997      90.120000\n",
       "26  sparse_categorical_crossentropy  Adadelta       89.099997      89.899999\n",
       "27                          poisson  Adadelta       85.675001      86.629999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sorted df\n",
    "df.sort_values(['Test Accuracy'],ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We were able to get 98.82% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
