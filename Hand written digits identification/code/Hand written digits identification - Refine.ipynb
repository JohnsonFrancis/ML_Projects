{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Implementaiton with ANN - Improving accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST handwritten digit data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#Lets do a min max scaling to make it between 0 & 1. This will be good for us in training.\n",
    "X_train=(X_train - X_train.min()) /(X_train.max() - X_train.min())\n",
    "X_test=(X_test - X_test.min()) /(X_test.max() - X_test.min())\n",
    "\n",
    "# Convert y_train into one-hot format \n",
    "y_train_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_hot = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly trying with 3 hidden layers with 100 nodes each. Also RELU activation is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note : model.fit includes an optional argument batch_size. If unspecified, batch_size will default to 32\n",
    "##### 60000/32 = 1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2393 - acc: 0.9284 - val_loss: 0.1440 - val_acc: 0.9560\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1040 - acc: 0.9685 - val_loss: 0.0971 - val_acc: 0.9700\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0758 - acc: 0.9766 - val_loss: 0.0896 - val_acc: 0.9726\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0606 - acc: 0.9810 - val_loss: 0.0841 - val_acc: 0.9734\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0493 - acc: 0.9835 - val_loss: 0.0982 - val_acc: 0.9714\n",
      "Train: 0.985, Test: 0.971\n"
     ]
    }
   ],
   "source": [
    "# Create simple Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))      # Input layer 784 neurons\n",
    "model.add(Dense(100, activation='relu'))     # 1st Hidden layer 100 neurons\n",
    "model.add(Dense(100, activation='relu'))     # 2nd Hidden layer 100 neurons\n",
    "model.add(Dense(100, activation='relu'))     # 3rd Hidden layer 100 neurons\n",
    "model.add(Dense(10, activation='softmax'))   # Output layer 10 neurons\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "# Train the Neural Network model\n",
    "\n",
    "model.fit(X_train, y_train_hot, epochs=5,validation_data=(X_test,y_test_hot))\n",
    "# evaluate the model...Verbose=0 is used to avoid report displays\n",
    "_, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got 97.1% accuracy with in 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now gonna try with different loss functions and optimizaers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaing lists of optimizers and loss functions\n",
    "loss=['categorical_crossentropy','kl_divergence','poisson','sparse_categorical_crossentropy']\n",
    "opt=['Adadelta','Adagrad','Adam','Adamax','Nadam','RMSprop','SGD']\n",
    "# Creating a dataframe for keeping results\n",
    "df=pd.DataFrame(columns =['Loss','Optimizer','Train Accuracy','Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: categorical_crossentropy, Optimizer: Adadelta, Train: 91.773, Test: 92.160\n",
      "Loss: categorical_crossentropy, Optimizer: Adagrad, Train: 96.517, Test: 96.120\n",
      "Loss: categorical_crossentropy, Optimizer: Adam, Train: 99.903, Test: 98.050\n",
      "Loss: categorical_crossentropy, Optimizer: Adamax, Train: 100.000, Test: 97.880\n",
      "Loss: categorical_crossentropy, Optimizer: Nadam, Train: 99.935, Test: 98.110\n",
      "Loss: categorical_crossentropy, Optimizer: RMSprop, Train: 99.857, Test: 97.720\n",
      "Loss: categorical_crossentropy, Optimizer: SGD, Train: 100.000, Test: 97.790\n",
      "Loss: kl_divergence, Optimizer: Adadelta, Train: 91.655, Test: 91.800\n",
      "Loss: kl_divergence, Optimizer: Adagrad, Train: 96.572, Test: 96.040\n",
      "Loss: kl_divergence, Optimizer: Adam, Train: 99.883, Test: 97.810\n",
      "Loss: kl_divergence, Optimizer: Adamax, Train: 99.997, Test: 97.780\n",
      "Loss: kl_divergence, Optimizer: Nadam, Train: 99.880, Test: 98.150\n",
      "Loss: kl_divergence, Optimizer: RMSprop, Train: 99.852, Test: 97.680\n",
      "Loss: kl_divergence, Optimizer: SGD, Train: 99.997, Test: 97.750\n",
      "Loss: poisson, Optimizer: Adadelta, Train: 89.858, Test: 90.250\n",
      "Loss: poisson, Optimizer: Adagrad, Train: 93.938, Test: 94.080\n",
      "Loss: poisson, Optimizer: Adam, Train: 99.880, Test: 97.890\n",
      "Loss: poisson, Optimizer: Adamax, Train: 100.000, Test: 97.870\n",
      "Loss: poisson, Optimizer: Nadam, Train: 99.860, Test: 97.800\n",
      "Loss: poisson, Optimizer: RMSprop, Train: 99.910, Test: 97.770\n",
      "Loss: poisson, Optimizer: SGD, Train: 97.902, Test: 96.740\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adadelta, Train: 91.557, Test: 91.770\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adagrad, Train: 96.502, Test: 96.080\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adam, Train: 99.865, Test: 97.850\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adamax, Train: 100.000, Test: 97.910\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Nadam, Train: 99.920, Test: 98.000\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: RMSprop, Train: 99.933, Test: 97.670\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: SGD, Train: 100.000, Test: 97.610\n"
     ]
    }
   ],
   "source": [
    "# Looping through all the possibilities with 100 Epocs.. This will run for a few hours.\n",
    "for l in loss:\n",
    "    for o in opt:\n",
    "        model=Sequential([  Flatten(input_shape=(28,28)),\n",
    "                            Dense(100,activation='relu'),\n",
    "                            Dense(100,activation='relu'),\n",
    "                            Dense(100,activation='relu'),\n",
    "                            Dense(10,activation='softmax')  ])                         \n",
    "        model.compile(optimizer=o, loss=l, metrics=['acc'])\n",
    "        if l == 'sparse_categorical_crossentropy': # No one hot encoding required for this\n",
    "            model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        else :\n",
    "            model.fit(X_train,y_train_hot,epochs=100,validation_data=(X_test,y_test_hot),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "        print('Loss: %s, Optimizer: %s, Train: %.3f, Test: %.3f' % (l,o,train_acc*100, test_acc*100))\n",
    "        df = df.append({'Loss':l,'Optimizer':o,'Train Accuracy':train_acc*100,'Test Accuracy':test_acc*100}, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.879998</td>\n",
       "      <td>98.150003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.935001</td>\n",
       "      <td>98.110002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.903333</td>\n",
       "      <td>98.049998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.919999</td>\n",
       "      <td>98.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.909999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.879998</td>\n",
       "      <td>97.890002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.869998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.865001</td>\n",
       "      <td>97.850001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.883336</td>\n",
       "      <td>97.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.860001</td>\n",
       "      <td>97.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.790003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.996668</td>\n",
       "      <td>97.780001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>poisson</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.910003</td>\n",
       "      <td>97.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.996668</td>\n",
       "      <td>97.750002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.856669</td>\n",
       "      <td>97.719997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.851668</td>\n",
       "      <td>97.680002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.933332</td>\n",
       "      <td>97.670001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.610003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>poisson</td>\n",
       "      <td>SGD</td>\n",
       "      <td>97.901666</td>\n",
       "      <td>96.740001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>96.516669</td>\n",
       "      <td>96.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>96.501666</td>\n",
       "      <td>96.079999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>96.571666</td>\n",
       "      <td>96.039999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>93.938333</td>\n",
       "      <td>94.080001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>91.773331</td>\n",
       "      <td>92.159998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>91.654998</td>\n",
       "      <td>91.799998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>91.556668</td>\n",
       "      <td>91.769999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>89.858335</td>\n",
       "      <td>90.249997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Loss Optimizer  Train Accuracy  Test Accuracy\n",
       "0                     kl_divergence     Nadam       99.879998      98.150003\n",
       "1          categorical_crossentropy     Nadam       99.935001      98.110002\n",
       "2          categorical_crossentropy      Adam       99.903333      98.049998\n",
       "3   sparse_categorical_crossentropy     Nadam       99.919999      98.000002\n",
       "4   sparse_categorical_crossentropy    Adamax      100.000000      97.909999\n",
       "5                           poisson      Adam       99.879998      97.890002\n",
       "6          categorical_crossentropy    Adamax      100.000000      97.880000\n",
       "7                           poisson    Adamax      100.000000      97.869998\n",
       "8   sparse_categorical_crossentropy      Adam       99.865001      97.850001\n",
       "9                     kl_divergence      Adam       99.883336      97.810000\n",
       "10                          poisson     Nadam       99.860001      97.799999\n",
       "11         categorical_crossentropy       SGD      100.000000      97.790003\n",
       "12                    kl_divergence    Adamax       99.996668      97.780001\n",
       "13                          poisson   RMSprop       99.910003      97.770000\n",
       "14                    kl_divergence       SGD       99.996668      97.750002\n",
       "15         categorical_crossentropy   RMSprop       99.856669      97.719997\n",
       "16                    kl_divergence   RMSprop       99.851668      97.680002\n",
       "17  sparse_categorical_crossentropy   RMSprop       99.933332      97.670001\n",
       "18  sparse_categorical_crossentropy       SGD      100.000000      97.610003\n",
       "19                          poisson       SGD       97.901666      96.740001\n",
       "20         categorical_crossentropy   Adagrad       96.516669      96.120000\n",
       "21  sparse_categorical_crossentropy   Adagrad       96.501666      96.079999\n",
       "22                    kl_divergence   Adagrad       96.571666      96.039999\n",
       "23                          poisson   Adagrad       93.938333      94.080001\n",
       "24         categorical_crossentropy  Adadelta       91.773331      92.159998\n",
       "25                    kl_divergence  Adadelta       91.654998      91.799998\n",
       "26  sparse_categorical_crossentropy  Adadelta       91.556668      91.769999\n",
       "27                          poisson  Adadelta       89.858335      90.249997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sorted df\n",
    "df.sort_values(['Test Accuracy'],ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We were able to get 98.15% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
