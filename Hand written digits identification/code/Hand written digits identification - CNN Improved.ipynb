{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Implementaiton with CNN - Improving accuracy #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/5588/1*k2xYkvn75VXOwzh726kILw.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST handwritten digit data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#Lets do a min max scaling to make it between 0 & 1. This will be good for us in training.\n",
    "X_train=(X_train - X_train.min()) /(X_train.max() - X_train.min())\n",
    "X_test=(X_test - X_test.min()) /(X_test.max() - X_test.min())\n",
    "\n",
    "# Convert y_train into one-hot format \n",
    "y_train_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_hot = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape dataset to have a single channel. Keras conv2d expects a 4 dim vector input\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly trying with a convolution layer and a pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 392s 209ms/step - loss: 0.1522 - acc: 0.9537 - val_loss: 0.0444 - val_acc: 0.9863\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 382s 204ms/step - loss: 0.0648 - acc: 0.9816 - val_loss: 0.0326 - val_acc: 0.9901\n",
      "Train: 0.990, Test: 0.990\n"
     ]
    }
   ],
   "source": [
    "# Create complex Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "# Train the Neural Network model\n",
    "model.fit(X_train, y_train_hot, epochs=2,validation_data=(X_test,y_test_hot))\n",
    "# evaluate the model...Verbose=0 is used to avoid report displays\n",
    "_, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got 98.3% accuracy with in 2 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now gonna try with different loss functions and optimizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaing lists of optimizers and loss functions\n",
    "loss=['categorical_crossentropy','kl_divergence','poisson','sparse_categorical_crossentropy']\n",
    "opt=['Adadelta','Adagrad','Adam','Adamax','Nadam','RMSprop','SGD']\n",
    "# Creating a dataframe for keeping results\n",
    "df=pd.DataFrame(columns =['Loss','Optimizer','Train Accuracy','Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: categorical_crossentropy, Optimizer: Adadelta, Train: 84.762, Test: 86.140\n",
      "Loss: categorical_crossentropy, Optimizer: Adagrad, Train: 97.465, Test: 97.540\n",
      "Loss: categorical_crossentropy, Optimizer: Adam, Train: 99.705, Test: 99.330\n",
      "Loss: categorical_crossentropy, Optimizer: Adamax, Train: 99.743, Test: 99.470\n",
      "Loss: categorical_crossentropy, Optimizer: Nadam, Train: 99.717, Test: 99.390\n",
      "Loss: categorical_crossentropy, Optimizer: RMSprop, Train: 98.902, Test: 98.720\n",
      "Loss: categorical_crossentropy, Optimizer: SGD, Train: 99.285, Test: 99.150\n",
      "Loss: kl_divergence, Optimizer: Adadelta, Train: 83.638, Test: 84.760\n",
      "Loss: kl_divergence, Optimizer: Adagrad, Train: 97.475, Test: 97.690\n",
      "Loss: kl_divergence, Optimizer: Adam, Train: 99.613, Test: 99.230\n",
      "Loss: kl_divergence, Optimizer: Adamax, Train: 99.677, Test: 99.380\n",
      "Loss: kl_divergence, Optimizer: Nadam, Train: 99.735, Test: 99.550\n",
      "Loss: kl_divergence, Optimizer: RMSprop, Train: 98.883, Test: 98.730\n",
      "Loss: kl_divergence, Optimizer: SGD, Train: 99.260, Test: 99.150\n",
      "Loss: poisson, Optimizer: Adadelta, Train: 45.523, Test: 47.030\n",
      "Loss: poisson, Optimizer: Adagrad, Train: 93.222, Test: 93.540\n",
      "Loss: poisson, Optimizer: Adam, Train: 99.792, Test: 99.540\n",
      "Loss: poisson, Optimizer: Adamax, Train: 99.680, Test: 99.440\n",
      "Loss: poisson, Optimizer: Nadam, Train: 99.767, Test: 99.430\n",
      "Loss: poisson, Optimizer: RMSprop, Train: 99.025, Test: 98.950\n",
      "Loss: poisson, Optimizer: SGD, Train: 96.978, Test: 97.070\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adadelta, Train: 85.255, Test: 86.490\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adagrad, Train: 97.243, Test: 97.480\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adam, Train: 99.757, Test: 99.510\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adamax, Train: 99.692, Test: 99.360\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Nadam, Train: 99.767, Test: 99.480\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: RMSprop, Train: 98.945, Test: 98.820\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: SGD, Train: 99.303, Test: 99.180\n"
     ]
    }
   ],
   "source": [
    "# Looping through all the possibilities with 10 Epocs.. This will run for a few hours.\n",
    "for l in loss:\n",
    "    for o in opt:\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "        model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation = \"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation = \"softmax\"))                        \n",
    "        model.compile(optimizer=o, loss=l, metrics=['acc'])\n",
    "        if l == 'sparse_categorical_crossentropy': # No one hot encoding required for this\n",
    "            model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        else :\n",
    "            model.fit(X_train,y_train_hot,epochs=10,validation_data=(X_test,y_test_hot),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "        print('Loss: %s, Optimizer: %s, Train: %.3f, Test: %.3f' % (l,o,train_acc*100, test_acc*100))\n",
    "        df = df.append({'Loss':l,'Optimizer':o,'Train Accuracy':train_acc*100,'Test Accuracy':test_acc*100}, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.734998</td>\n",
       "      <td>99.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.791664</td>\n",
       "      <td>99.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.756664</td>\n",
       "      <td>99.510002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.766666</td>\n",
       "      <td>99.479997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.743330</td>\n",
       "      <td>99.470001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.680001</td>\n",
       "      <td>99.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.766666</td>\n",
       "      <td>99.430001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.716669</td>\n",
       "      <td>99.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.676669</td>\n",
       "      <td>99.379998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.691665</td>\n",
       "      <td>99.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.704999</td>\n",
       "      <td>99.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.613333</td>\n",
       "      <td>99.229997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.303335</td>\n",
       "      <td>99.180001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.260002</td>\n",
       "      <td>99.150002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.285001</td>\n",
       "      <td>99.150002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>poisson</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.024999</td>\n",
       "      <td>98.949999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>98.944998</td>\n",
       "      <td>98.820001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>98.883331</td>\n",
       "      <td>98.729998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>98.901665</td>\n",
       "      <td>98.720002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>97.474998</td>\n",
       "      <td>97.689998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>97.465003</td>\n",
       "      <td>97.539997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>97.243333</td>\n",
       "      <td>97.479999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>poisson</td>\n",
       "      <td>SGD</td>\n",
       "      <td>96.978331</td>\n",
       "      <td>97.070003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>93.221664</td>\n",
       "      <td>93.540001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>85.255003</td>\n",
       "      <td>86.489999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>84.761667</td>\n",
       "      <td>86.140001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>83.638334</td>\n",
       "      <td>84.759998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>45.523334</td>\n",
       "      <td>47.029999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Loss Optimizer  Train Accuracy  Test Accuracy\n",
       "0                     kl_divergence     Nadam       99.734998      99.550003\n",
       "1                           poisson      Adam       99.791664      99.540001\n",
       "2   sparse_categorical_crossentropy      Adam       99.756664      99.510002\n",
       "3   sparse_categorical_crossentropy     Nadam       99.766666      99.479997\n",
       "4          categorical_crossentropy    Adamax       99.743330      99.470001\n",
       "5                           poisson    Adamax       99.680001      99.440002\n",
       "6                           poisson     Nadam       99.766666      99.430001\n",
       "7          categorical_crossentropy     Nadam       99.716669      99.390000\n",
       "8                     kl_divergence    Adamax       99.676669      99.379998\n",
       "9   sparse_categorical_crossentropy    Adamax       99.691665      99.360001\n",
       "10         categorical_crossentropy      Adam       99.704999      99.330002\n",
       "11                    kl_divergence      Adam       99.613333      99.229997\n",
       "12  sparse_categorical_crossentropy       SGD       99.303335      99.180001\n",
       "13                    kl_divergence       SGD       99.260002      99.150002\n",
       "14         categorical_crossentropy       SGD       99.285001      99.150002\n",
       "15                          poisson   RMSprop       99.024999      98.949999\n",
       "16  sparse_categorical_crossentropy   RMSprop       98.944998      98.820001\n",
       "17                    kl_divergence   RMSprop       98.883331      98.729998\n",
       "18         categorical_crossentropy   RMSprop       98.901665      98.720002\n",
       "19                    kl_divergence   Adagrad       97.474998      97.689998\n",
       "20         categorical_crossentropy   Adagrad       97.465003      97.539997\n",
       "21  sparse_categorical_crossentropy   Adagrad       97.243333      97.479999\n",
       "22                          poisson       SGD       96.978331      97.070003\n",
       "23                          poisson   Adagrad       93.221664      93.540001\n",
       "24  sparse_categorical_crossentropy  Adadelta       85.255003      86.489999\n",
       "25         categorical_crossentropy  Adadelta       84.761667      86.140001\n",
       "26                    kl_divergence  Adadelta       83.638334      84.759998\n",
       "27                          poisson  Adadelta       45.523334      47.029999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sorted df\n",
    "df.sort_values(['Test Accuracy'],ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We were able to get 99.55% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
