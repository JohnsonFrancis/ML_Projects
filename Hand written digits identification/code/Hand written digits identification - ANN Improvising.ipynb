{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Implementaiton with ANN - Improving accuracy #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST handwritten digit data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#Lets do a min max scaling to make it between 0 & 1. This will be good for us in training.\n",
    "X_train=(X_train - X_train.min()) /(X_train.max() - X_train.min())\n",
    "X_test=(X_test - X_test.min()) /(X_test.max() - X_test.min())\n",
    "\n",
    "# Convert y_train into one-hot format \n",
    "y_train_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_hot = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly trying with 3 hidden layers with 100 nodes each. Also RELU activation is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note : model.fit includes an optional argument batch_size. If unspecified, batch_size will default to 32\n",
    "##### 60000/32 = 1875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 99,710\n",
      "Trainable params: 99,710\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2406 - acc: 0.9279 - val_loss: 0.1315 - val_acc: 0.9576\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1066 - acc: 0.9667 - val_loss: 0.1009 - val_acc: 0.9688\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0750 - acc: 0.9765 - val_loss: 0.1120 - val_acc: 0.9665\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0608 - acc: 0.9808 - val_loss: 0.0900 - val_acc: 0.9743\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0479 - acc: 0.9845 - val_loss: 0.0821 - val_acc: 0.9767\n",
      "Train: 0.991, Test: 0.977\n"
     ]
    }
   ],
   "source": [
    "# Create simple Neural Network model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))      # Input layer 784 neurons\n",
    "model.add(Dense(100, activation='relu'))     # 1st Hidden layer 100 neurons\n",
    "model.add(Dense(100, activation='relu'))     # 2nd Hidden layer 100 neurons\n",
    "model.add(Dense(100, activation='relu'))     # 3rd Hidden layer 100 neurons\n",
    "model.add(Dense(10, activation='softmax'))   # Output layer 10 neurons\n",
    "model.summary()\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "# Train the Neural Network model\n",
    "\n",
    "model.fit(X_train, y_train_hot, epochs=5,validation_data=(X_test,y_test_hot))\n",
    "# evaluate the model...Verbose=0 is used to avoid report displays\n",
    "_, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Got 97.6% accuracy with in 5 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now gonna try with different loss functions and optimizaers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaing lists of optimizers and loss functions\n",
    "loss=['categorical_crossentropy','kl_divergence','poisson','sparse_categorical_crossentropy']\n",
    "opt=['Adadelta','Adagrad','Adam','Adamax','Nadam','RMSprop','SGD']\n",
    "# Creating a dataframe for keeping results\n",
    "df=pd.DataFrame(columns =['Loss','Optimizer','Train Accuracy','Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: categorical_crossentropy, Optimizer: Adadelta, Train: 93.742, Test: 93.680\n",
      "Loss: categorical_crossentropy, Optimizer: Adagrad, Train: 97.620, Test: 96.780\n",
      "Loss: categorical_crossentropy, Optimizer: Adam, Train: 99.908, Test: 97.780\n",
      "Loss: categorical_crossentropy, Optimizer: Adamax, Train: 100.000, Test: 97.840\n",
      "Loss: categorical_crossentropy, Optimizer: Nadam, Train: 99.923, Test: 98.060\n",
      "Loss: categorical_crossentropy, Optimizer: RMSprop, Train: 99.963, Test: 97.960\n",
      "Loss: categorical_crossentropy, Optimizer: SGD, Train: 100.000, Test: 97.720\n",
      "Loss: kl_divergence, Optimizer: Adadelta, Train: 93.622, Test: 93.800\n",
      "Loss: kl_divergence, Optimizer: Adagrad, Train: 97.345, Test: 96.490\n",
      "Loss: kl_divergence, Optimizer: Adam, Train: 99.955, Test: 98.100\n",
      "Loss: kl_divergence, Optimizer: Adamax, Train: 99.998, Test: 97.950\n",
      "Loss: kl_divergence, Optimizer: Nadam, Train: 99.872, Test: 97.880\n",
      "Loss: kl_divergence, Optimizer: RMSprop, Train: 99.888, Test: 97.790\n",
      "Loss: kl_divergence, Optimizer: SGD, Train: 99.998, Test: 97.860\n",
      "Loss: poisson, Optimizer: Adadelta, Train: 92.127, Test: 92.490\n",
      "Loss: poisson, Optimizer: Adagrad, Train: 95.637, Test: 95.230\n",
      "Loss: poisson, Optimizer: Adam, Train: 99.952, Test: 98.070\n",
      "Loss: poisson, Optimizer: Adamax, Train: 99.998, Test: 97.900\n",
      "Loss: poisson, Optimizer: Nadam, Train: 99.940, Test: 97.970\n",
      "Loss: poisson, Optimizer: RMSprop, Train: 99.967, Test: 97.890\n",
      "Loss: poisson, Optimizer: SGD, Train: 99.232, Test: 97.460\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adadelta, Train: 93.723, Test: 93.750\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adagrad, Train: 97.493, Test: 96.620\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adam, Train: 99.968, Test: 98.240\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Adamax, Train: 100.000, Test: 97.870\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: Nadam, Train: 99.860, Test: 97.920\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: RMSprop, Train: 99.890, Test: 97.780\n",
      "Loss: sparse_categorical_crossentropy, Optimizer: SGD, Train: 100.000, Test: 97.840\n"
     ]
    }
   ],
   "source": [
    "# Looping through all the possibilities with 200 Epocs.. This will run for a few hours.\n",
    "for l in loss:\n",
    "    for o in opt:\n",
    "        model=Sequential([  Flatten(input_shape=(28,28)),\n",
    "                            Dense(100,activation='relu'),\n",
    "                            Dense(100,activation='relu'),\n",
    "                            Dense(100,activation='relu'),\n",
    "                            Dense(10,activation='softmax')  ])                         \n",
    "        model.compile(optimizer=o, loss=l, metrics=['acc'])\n",
    "        if l == 'sparse_categorical_crossentropy': # No one hot encoding required for this\n",
    "            model.fit(X_train,y_train,epochs=200,validation_data=(X_test,y_test),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "        else :\n",
    "            model.fit(X_train,y_train_hot,epochs=200,validation_data=(X_test,y_test_hot),verbose=0)\n",
    "            _, train_acc = model.evaluate(X_train, y_train_hot, verbose=0)\n",
    "            _, test_acc = model.evaluate(X_test, y_test_hot, verbose=0)\n",
    "        print('Loss: %s, Optimizer: %s, Train: %.3f, Test: %.3f' % (l,o,train_acc*100, test_acc*100))\n",
    "        df = df.append({'Loss':l,'Optimizer':o,'Train Accuracy':train_acc*100,'Test Accuracy':test_acc*100}, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.968332</td>\n",
       "      <td>98.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.954998</td>\n",
       "      <td>98.100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.951667</td>\n",
       "      <td>98.070002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.923331</td>\n",
       "      <td>98.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.940002</td>\n",
       "      <td>97.970003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.963331</td>\n",
       "      <td>97.960001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.998331</td>\n",
       "      <td>97.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.860001</td>\n",
       "      <td>97.920001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>99.998331</td>\n",
       "      <td>97.899997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>poisson</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.966669</td>\n",
       "      <td>97.890002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>99.871665</td>\n",
       "      <td>97.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.869998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.998331</td>\n",
       "      <td>97.860003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.839999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.839999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.888331</td>\n",
       "      <td>97.790003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>99.890000</td>\n",
       "      <td>97.780001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adam</td>\n",
       "      <td>99.908334</td>\n",
       "      <td>97.780001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>SGD</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>97.719997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>poisson</td>\n",
       "      <td>SGD</td>\n",
       "      <td>99.231666</td>\n",
       "      <td>97.460002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>97.619998</td>\n",
       "      <td>96.780002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>97.493333</td>\n",
       "      <td>96.619999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>97.345001</td>\n",
       "      <td>96.490002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>95.636666</td>\n",
       "      <td>95.230001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kl_divergence</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>93.621665</td>\n",
       "      <td>93.800002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sparse_categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>93.723333</td>\n",
       "      <td>93.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>93.741667</td>\n",
       "      <td>93.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>poisson</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>92.126667</td>\n",
       "      <td>92.490000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Loss Optimizer  Train Accuracy  Test Accuracy\n",
       "0   sparse_categorical_crossentropy      Adam       99.968332      98.240000\n",
       "1                     kl_divergence      Adam       99.954998      98.100001\n",
       "2                           poisson      Adam       99.951667      98.070002\n",
       "3          categorical_crossentropy     Nadam       99.923331      98.060000\n",
       "4                           poisson     Nadam       99.940002      97.970003\n",
       "5          categorical_crossentropy   RMSprop       99.963331      97.960001\n",
       "6                     kl_divergence    Adamax       99.998331      97.950000\n",
       "7   sparse_categorical_crossentropy     Nadam       99.860001      97.920001\n",
       "8                           poisson    Adamax       99.998331      97.899997\n",
       "9                           poisson   RMSprop       99.966669      97.890002\n",
       "10                    kl_divergence     Nadam       99.871665      97.880000\n",
       "11  sparse_categorical_crossentropy    Adamax      100.000000      97.869998\n",
       "12                    kl_divergence       SGD       99.998331      97.860003\n",
       "13         categorical_crossentropy    Adamax      100.000000      97.839999\n",
       "14  sparse_categorical_crossentropy       SGD      100.000000      97.839999\n",
       "15                    kl_divergence   RMSprop       99.888331      97.790003\n",
       "16  sparse_categorical_crossentropy   RMSprop       99.890000      97.780001\n",
       "17         categorical_crossentropy      Adam       99.908334      97.780001\n",
       "18         categorical_crossentropy       SGD      100.000000      97.719997\n",
       "19                          poisson       SGD       99.231666      97.460002\n",
       "20         categorical_crossentropy   Adagrad       97.619998      96.780002\n",
       "21  sparse_categorical_crossentropy   Adagrad       97.493333      96.619999\n",
       "22                    kl_divergence   Adagrad       97.345001      96.490002\n",
       "23                          poisson   Adagrad       95.636666      95.230001\n",
       "24                    kl_divergence  Adadelta       93.621665      93.800002\n",
       "25  sparse_categorical_crossentropy  Adadelta       93.723333      93.750000\n",
       "26         categorical_crossentropy  Adadelta       93.741667      93.680000\n",
       "27                          poisson  Adadelta       92.126667      92.490000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sorted df\n",
    "df.sort_values(['Test Accuracy'],ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We were able to get 98.24% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
